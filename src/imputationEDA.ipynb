{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acknowledge that the dataset herein is miniature and can be toyed with on Jupyter nb using a local machine, perhaps with single GPU. More realistic datasets would require API interfacing with a cluster and data engineering pipelines to display distributions of billions of params over time, or to run robust imputation methods for missing data as standalone endeavors before one even considers modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train_sparked.csv\")\n",
    "X_test_nulls_raw = pd.read_csv(\"../data/test_sparked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SellerCity</th>\n",
       "      <th>SellerIsPriv</th>\n",
       "      <th>SellerListSrc</th>\n",
       "      <th>SellerName</th>\n",
       "      <th>SellerRating</th>\n",
       "      <th>SellerRevCnt</th>\n",
       "      <th>SellerState</th>\n",
       "      <th>SellerZip</th>\n",
       "      <th>VehCertified</th>\n",
       "      <th>VehColorExt</th>\n",
       "      <th>...</th>\n",
       "      <th>VehListdays</th>\n",
       "      <th>VehMake</th>\n",
       "      <th>VehMileage</th>\n",
       "      <th>VehModel</th>\n",
       "      <th>VehPriceLabel</th>\n",
       "      <th>VehSellerNotes</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>Vehicle_Trim</th>\n",
       "      <th>Dealer_Listing_Price</th>\n",
       "      <th>NumOwners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warren</td>\n",
       "      <td>False</td>\n",
       "      <td>inventorycommandcenter</td>\n",
       "      <td>primemotorz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32</td>\n",
       "      <td>MI</td>\n",
       "      <td>48091</td>\n",
       "      <td>False</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>8.600069</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>39319</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>fairprice</td>\n",
       "      <td>None.</td>\n",
       "      <td>2015</td>\n",
       "      <td>High Altitude</td>\n",
       "      <td>30990.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fargo</td>\n",
       "      <td>False</td>\n",
       "      <td>cadillaccertifiedprogram</td>\n",
       "      <td>gatewaychevroletcadillac</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1456</td>\n",
       "      <td>ND</td>\n",
       "      <td>58103</td>\n",
       "      <td>True</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>2.920127</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>30352</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Come take a look at our great pre-owned invent...</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34860.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waukesha</td>\n",
       "      <td>False</td>\n",
       "      <td>jeepcertifiedprogram</td>\n",
       "      <td>wildechryslerjeepdodgeramampsubaru</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1405</td>\n",
       "      <td>WI</td>\n",
       "      <td>53186</td>\n",
       "      <td>True</td>\n",
       "      <td>brilliantblackcrystalpearlcoat</td>\n",
       "      <td>...</td>\n",
       "      <td>28.107014</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>38957</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Backed by a rigorous 125-point inspection by f...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Laredo</td>\n",
       "      <td>23249.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wentzville</td>\n",
       "      <td>False</td>\n",
       "      <td>inventorycommandcenter</td>\n",
       "      <td>centurydodgechryslerjeepram</td>\n",
       "      <td>4.4</td>\n",
       "      <td>21</td>\n",
       "      <td>MO</td>\n",
       "      <td>63385</td>\n",
       "      <td>False</td>\n",
       "      <td>diamondblackcrystalpearlcoat</td>\n",
       "      <td>...</td>\n",
       "      <td>59.816875</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>20404</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Drop by to see us and you will quickly see how...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Limited</td>\n",
       "      <td>31977.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fayetteville</td>\n",
       "      <td>False</td>\n",
       "      <td>homenetautomotive</td>\n",
       "      <td>superiorbuickgmcoffayetteville</td>\n",
       "      <td>3.7</td>\n",
       "      <td>74</td>\n",
       "      <td>AR</td>\n",
       "      <td>72703</td>\n",
       "      <td>False</td>\n",
       "      <td>radiantsilvermetallic</td>\n",
       "      <td>...</td>\n",
       "      <td>98.665301</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>19788</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Luxury, Exterior Parking Camera Rear, Front Du...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>33495.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>dearborn</td>\n",
       "      <td>True</td>\n",
       "      <td>sellityourself</td>\n",
       "      <td>abe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>MI</td>\n",
       "      <td>48126</td>\n",
       "      <td>False</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>29.781968</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>49000</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>****ALL BLACK EDITION****You are viewing a bea...</td>\n",
       "      <td>2015</td>\n",
       "      <td>High Altitude</td>\n",
       "      <td>18699.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>indianapolis</td>\n",
       "      <td>False</td>\n",
       "      <td>digitalmotorworksdmi</td>\n",
       "      <td>carmaxindianapolis</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16</td>\n",
       "      <td>IN</td>\n",
       "      <td>46280</td>\n",
       "      <td>False</td>\n",
       "      <td>gray</td>\n",
       "      <td>...</td>\n",
       "      <td>4.840069</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>20039</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>fairprice</td>\n",
       "      <td>CarMax makes car buying easy and hassle-free. ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Limited</td>\n",
       "      <td>31998.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>dublin</td>\n",
       "      <td>False</td>\n",
       "      <td>digitalmotorworksdmi</td>\n",
       "      <td>cadillacofdublin</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20</td>\n",
       "      <td>OH</td>\n",
       "      <td>43017</td>\n",
       "      <td>True</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>184.921991</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>16278</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Clean CARFAX. Certified. Black 2018 Cadillac X...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>35674.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>sandusky</td>\n",
       "      <td>False</td>\n",
       "      <td>digitalmotorworksdmi</td>\n",
       "      <td>fosterchevroletcadillac</td>\n",
       "      <td>4.9</td>\n",
       "      <td>278</td>\n",
       "      <td>OH</td>\n",
       "      <td>44870</td>\n",
       "      <td>False</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>73.868426</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>38146</td>\n",
       "      <td>xt5</td>\n",
       "      <td>greatdeal</td>\n",
       "      <td>Black 2017 Cadillac XT5 Luxury FWD 8-Speed Aut...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>31995.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>nashville</td>\n",
       "      <td>False</td>\n",
       "      <td>homenetautomotive</td>\n",
       "      <td>vroomonlinedealernationwidedelivery</td>\n",
       "      <td>3.8</td>\n",
       "      <td>727</td>\n",
       "      <td>TN</td>\n",
       "      <td>37207</td>\n",
       "      <td>False</td>\n",
       "      <td>diamondblackcrystalpearlcoat</td>\n",
       "      <td>...</td>\n",
       "      <td>20.678600</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>17806</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>With Vroom, you can buy your next car from the...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Trailhawk</td>\n",
       "      <td>36280.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6294 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SellerCity  SellerIsPriv             SellerListSrc  \\\n",
       "0           warren         False    inventorycommandcenter   \n",
       "1            fargo         False  cadillaccertifiedprogram   \n",
       "2         waukesha         False      jeepcertifiedprogram   \n",
       "3       wentzville         False    inventorycommandcenter   \n",
       "4     fayetteville         False         homenetautomotive   \n",
       "...            ...           ...                       ...   \n",
       "6289      dearborn          True            sellityourself   \n",
       "6290  indianapolis         False      digitalmotorworksdmi   \n",
       "6291        dublin         False      digitalmotorworksdmi   \n",
       "6292      sandusky         False      digitalmotorworksdmi   \n",
       "6293     nashville         False         homenetautomotive   \n",
       "\n",
       "                               SellerName  SellerRating  SellerRevCnt  \\\n",
       "0                             primemotorz           5.0            32   \n",
       "1                gatewaychevroletcadillac           4.8          1456   \n",
       "2      wildechryslerjeepdodgeramampsubaru           4.8          1405   \n",
       "3             centurydodgechryslerjeepram           4.4            21   \n",
       "4          superiorbuickgmcoffayetteville           3.7            74   \n",
       "...                                   ...           ...           ...   \n",
       "6289                                  abe           0.0             0   \n",
       "6290                   carmaxindianapolis           3.3            16   \n",
       "6291                     cadillacofdublin           4.1            20   \n",
       "6292              fosterchevroletcadillac           4.9           278   \n",
       "6293  vroomonlinedealernationwidedelivery           3.8           727   \n",
       "\n",
       "     SellerState  SellerZip  VehCertified                     VehColorExt  \\\n",
       "0             MI      48091         False                           white   \n",
       "1             ND      58103          True                           black   \n",
       "2             WI      53186          True  brilliantblackcrystalpearlcoat   \n",
       "3             MO      63385         False    diamondblackcrystalpearlcoat   \n",
       "4             AR      72703         False           radiantsilvermetallic   \n",
       "...          ...        ...           ...                             ...   \n",
       "6289          MI      48126         False                           black   \n",
       "6290          IN      46280         False                            gray   \n",
       "6291          OH      43017          True                           black   \n",
       "6292          OH      44870         False                           black   \n",
       "6293          TN      37207         False    diamondblackcrystalpearlcoat   \n",
       "\n",
       "      ... VehListdays   VehMake VehMileage       VehModel VehPriceLabel  \\\n",
       "0     ...    8.600069      Jeep      39319  grandcherokee     fairprice   \n",
       "1     ...    2.920127  Cadillac      30352            xt5      gooddeal   \n",
       "2     ...   28.107014      Jeep      38957  grandcherokee      gooddeal   \n",
       "3     ...   59.816875      Jeep      20404  grandcherokee      gooddeal   \n",
       "4     ...   98.665301  Cadillac      19788            xt5      gooddeal   \n",
       "...   ...         ...       ...        ...            ...           ...   \n",
       "6289  ...   29.781968      Jeep      49000  grandcherokee           NaN   \n",
       "6290  ...    4.840069      Jeep      20039  grandcherokee     fairprice   \n",
       "6291  ...  184.921991  Cadillac      16278            xt5      gooddeal   \n",
       "6292  ...   73.868426  Cadillac      38146            xt5     greatdeal   \n",
       "6293  ...   20.678600      Jeep      17806  grandcherokee      gooddeal   \n",
       "\n",
       "                                         VehSellerNotes  VehYear  \\\n",
       "0                                                 None.     2015   \n",
       "1     Come take a look at our great pre-owned invent...     2017   \n",
       "2     Backed by a rigorous 125-point inspection by f...     2015   \n",
       "3     Drop by to see us and you will quickly see how...     2018   \n",
       "4     Luxury, Exterior Parking Camera Rear, Front Du...     2018   \n",
       "...                                                 ...      ...   \n",
       "6289  ****ALL BLACK EDITION****You are viewing a bea...     2015   \n",
       "6290  CarMax makes car buying easy and hassle-free. ...     2015   \n",
       "6291  Clean CARFAX. Certified. Black 2018 Cadillac X...     2018   \n",
       "6292  Black 2017 Cadillac XT5 Luxury FWD 8-Speed Aut...     2017   \n",
       "6293  With Vroom, you can buy your next car from the...     2018   \n",
       "\n",
       "       Vehicle_Trim  Dealer_Listing_Price NumOwners  \n",
       "0     High Altitude               30990.0       1.0  \n",
       "1               NaN               34860.0       1.0  \n",
       "2            Laredo               23249.0       1.0  \n",
       "3           Limited               31977.0       1.0  \n",
       "4            Luxury               33495.0       1.0  \n",
       "...             ...                   ...       ...  \n",
       "6289  High Altitude               18699.0       NaN  \n",
       "6290        Limited               31998.0       1.0  \n",
       "6291         Luxury               35674.0       0.0  \n",
       "6292         Luxury               31995.0       2.0  \n",
       "6293      Trailhawk               36280.0       1.0  \n",
       "\n",
       "[6294 rows x 26 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SellerCity               object\n",
       "SellerIsPriv               bool\n",
       "SellerListSrc            object\n",
       "SellerName               object\n",
       "SellerRating            float64\n",
       "SellerRevCnt              int64\n",
       "SellerState              object\n",
       "SellerZip                 int64\n",
       "VehCertified               bool\n",
       "VehColorExt              object\n",
       "VehColorInt              object\n",
       "VehDriveTrain            object\n",
       "VehEngine                object\n",
       "VehFeats                 object\n",
       "VehFuel                  object\n",
       "VehHistory               object\n",
       "VehListdays             float64\n",
       "VehMake                  object\n",
       "VehMileage                int64\n",
       "VehModel                 object\n",
       "VehPriceLabel            object\n",
       "VehSellerNotes           object\n",
       "VehYear                   int64\n",
       "Vehicle_Trim             object\n",
       "Dealer_Listing_Price    float64\n",
       "NumOwners               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data[\"Word2Vec_VehSellerNotes\"].unique()), len(data[\"Word2Vec_SellerName\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SellerCity               object\n",
       "SellerIsPriv               bool\n",
       "SellerListSrc            object\n",
       "SellerName               object\n",
       "SellerRating            float64\n",
       "SellerRevCnt              int64\n",
       "SellerState              object\n",
       "SellerZip                 int64\n",
       "VehCertified               bool\n",
       "VehColorExt              object\n",
       "VehColorInt              object\n",
       "VehDriveTrain            object\n",
       "VehEngine                object\n",
       "VehFeats                 object\n",
       "VehFuel                  object\n",
       "VehHistory               object\n",
       "VehListdays             float64\n",
       "VehMake                  object\n",
       "VehMileage                int64\n",
       "VehModel                 object\n",
       "VehPriceLabel            object\n",
       "VehSellerNotes           object\n",
       "VehYear                   int64\n",
       "Vehicle_Trim             object\n",
       "Dealer_Listing_Price    float64\n",
       "NumOwners               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingID</th>\n",
       "      <th>SellerCity</th>\n",
       "      <th>SellerIsPriv</th>\n",
       "      <th>SellerListSrc</th>\n",
       "      <th>SellerName</th>\n",
       "      <th>SellerRating</th>\n",
       "      <th>SellerRevCnt</th>\n",
       "      <th>SellerState</th>\n",
       "      <th>SellerZip</th>\n",
       "      <th>VehCertified</th>\n",
       "      <th>...</th>\n",
       "      <th>VehFuel</th>\n",
       "      <th>VehHistory</th>\n",
       "      <th>VehListdays</th>\n",
       "      <th>VehMake</th>\n",
       "      <th>VehMileage</th>\n",
       "      <th>VehModel</th>\n",
       "      <th>VehPriceLabel</th>\n",
       "      <th>VehSellerNotes</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>NumOwners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8622015</td>\n",
       "      <td>seneca</td>\n",
       "      <td>False</td>\n",
       "      <td>homenetautomotive</td>\n",
       "      <td>lakekeoweechryslerdodgejeepram</td>\n",
       "      <td>2.5</td>\n",
       "      <td>59</td>\n",
       "      <td>SC</td>\n",
       "      <td>29678</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['non-personal use reported', 'buyback protect...</td>\n",
       "      <td>143.991262</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>13625.0</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Thank you for visiting another one of Lake Keo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8625693</td>\n",
       "      <td>bedford</td>\n",
       "      <td>False</td>\n",
       "      <td>inventorycommandcenter</td>\n",
       "      <td>northcoastautomall</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2116</td>\n",
       "      <td>OH</td>\n",
       "      <td>44146</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['accident(s) reported', 'non-personal use rep...</td>\n",
       "      <td>138.770486</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>42553.0</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>This 2017 Jeep Grand Cherokee 4dr Limited 4x4 ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8625750</td>\n",
       "      <td>webster</td>\n",
       "      <td>False</td>\n",
       "      <td>jeepcertifiedprogram</td>\n",
       "      <td>marinachryslerdodgejeepmitsubishiram</td>\n",
       "      <td>3.9</td>\n",
       "      <td>46</td>\n",
       "      <td>NY</td>\n",
       "      <td>14580</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>E85 Flex Fuel</td>\n",
       "      <td>['buyback protection eligible']</td>\n",
       "      <td>31.951088</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>48951.0</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Certified. Brilliant Black Crystal Pearlcoat 2...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8626885</td>\n",
       "      <td>louisville</td>\n",
       "      <td>False</td>\n",
       "      <td>digitalmotorworksdmi</td>\n",
       "      <td>oxmoorfordlincoln</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1075</td>\n",
       "      <td>KY</td>\n",
       "      <td>40222</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['buyback protection eligible']</td>\n",
       "      <td>5.950127</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>44179.0</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>2015 Jeep Grand Cherokee ***THIS VEHICLE IS AT...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8627430</td>\n",
       "      <td>palmyra</td>\n",
       "      <td>False</td>\n",
       "      <td>digitalmotorworksdmi</td>\n",
       "      <td>fckerbeckampsons</td>\n",
       "      <td>4.6</td>\n",
       "      <td>162</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8065</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['non-personal use reported', 'buyback protect...</td>\n",
       "      <td>24.672986</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>22269.0</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>AWD, CarFax One Owner! Navigation, Back-up Cam...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>9992442</td>\n",
       "      <td>forestpark</td>\n",
       "      <td>False</td>\n",
       "      <td>homenetautomotive</td>\n",
       "      <td>curriechevy</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1081</td>\n",
       "      <td>IL</td>\n",
       "      <td>60130</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['buyback protection eligible']</td>\n",
       "      <td>18.091597</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>24744.0</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>granite crystal metallic clearcoat 2017 Jeep G...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>9993562</td>\n",
       "      <td>tampa</td>\n",
       "      <td>False</td>\n",
       "      <td>inventorycommandcenter</td>\n",
       "      <td>tampamitsubishi</td>\n",
       "      <td>4.0</td>\n",
       "      <td>240</td>\n",
       "      <td>FL</td>\n",
       "      <td>33614</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['non-personal use reported', 'buyback protect...</td>\n",
       "      <td>167.799676</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>5699.0</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Tampa Mitsubishi is proud to offer this attrac...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>9994646</td>\n",
       "      <td>tampa</td>\n",
       "      <td>False</td>\n",
       "      <td>homenetautomotive</td>\n",
       "      <td>fermanacura</td>\n",
       "      <td>5.0</td>\n",
       "      <td>134</td>\n",
       "      <td>FL</td>\n",
       "      <td>33612</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['accident(s) reported', 'non-personal use rep...</td>\n",
       "      <td>46.215625</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>17985.0</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>*BRAND NEW* *2018* *CADILLAC* *XT5** LOADED WI...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>9997199</td>\n",
       "      <td>hamburg</td>\n",
       "      <td>False</td>\n",
       "      <td>inventorycommandcenter</td>\n",
       "      <td>townechryslerdodgejeepraminc</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7</td>\n",
       "      <td>NY</td>\n",
       "      <td>14075</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>['buyback protection eligible']</td>\n",
       "      <td>14.907535</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>27.0</td>\n",
       "      <td>grandcherokee</td>\n",
       "      <td>fairprice</td>\n",
       "      <td>Thousand?s of Vehicles, Positively Different E...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9999562</td>\n",
       "      <td>rocksprings</td>\n",
       "      <td>False</td>\n",
       "      <td>digitalmotorworksdmi</td>\n",
       "      <td>whislerchevrolet</td>\n",
       "      <td>4.9</td>\n",
       "      <td>28</td>\n",
       "      <td>WY</td>\n",
       "      <td>82901</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>['non-personal use reported', 'buyback protect...</td>\n",
       "      <td>144.833935</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>23435.0</td>\n",
       "      <td>xt5</td>\n",
       "      <td>gooddeal</td>\n",
       "      <td>Features: 2018 Cadillac XT5 Luxury Red AWD 3.6...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ListingID   SellerCity  SellerIsPriv           SellerListSrc  \\\n",
       "0      8622015       seneca         False       homenetautomotive   \n",
       "1      8625693      bedford         False  inventorycommandcenter   \n",
       "2      8625750      webster         False    jeepcertifiedprogram   \n",
       "3      8626885   louisville         False    digitalmotorworksdmi   \n",
       "4      8627430      palmyra         False    digitalmotorworksdmi   \n",
       "..         ...          ...           ...                     ...   \n",
       "995    9992442   forestpark         False       homenetautomotive   \n",
       "996    9993562        tampa         False  inventorycommandcenter   \n",
       "997    9994646        tampa         False       homenetautomotive   \n",
       "998    9997199      hamburg         False  inventorycommandcenter   \n",
       "999    9999562  rocksprings         False    digitalmotorworksdmi   \n",
       "\n",
       "                               SellerName  SellerRating  SellerRevCnt  \\\n",
       "0          lakekeoweechryslerdodgejeepram           2.5            59   \n",
       "1                      northcoastautomall           4.7          2116   \n",
       "2    marinachryslerdodgejeepmitsubishiram           3.9            46   \n",
       "3                       oxmoorfordlincoln           4.5          1075   \n",
       "4                        fckerbeckampsons           4.6           162   \n",
       "..                                    ...           ...           ...   \n",
       "995                           curriechevy           4.8          1081   \n",
       "996                       tampamitsubishi           4.0           240   \n",
       "997                           fermanacura           5.0           134   \n",
       "998          townechryslerdodgejeepraminc           3.8             7   \n",
       "999                      whislerchevrolet           4.9            28   \n",
       "\n",
       "    SellerState  SellerZip  VehCertified  ...        VehFuel  \\\n",
       "0            SC      29678         False  ...       Gasoline   \n",
       "1            OH      44146         False  ...       Gasoline   \n",
       "2            NY      14580          True  ...  E85 Flex Fuel   \n",
       "3            KY      40222         False  ...       Gasoline   \n",
       "4            NJ       8065         False  ...       Gasoline   \n",
       "..          ...        ...           ...  ...            ...   \n",
       "995          IL      60130         False  ...       Gasoline   \n",
       "996          FL      33614         False  ...       Gasoline   \n",
       "997          FL      33612         False  ...       Gasoline   \n",
       "998          NY      14075         False  ...         Diesel   \n",
       "999          WY      82901         False  ...       Gasoline   \n",
       "\n",
       "                                            VehHistory VehListdays   VehMake  \\\n",
       "0    ['non-personal use reported', 'buyback protect...  143.991262  Cadillac   \n",
       "1    ['accident(s) reported', 'non-personal use rep...  138.770486      Jeep   \n",
       "2                      ['buyback protection eligible']   31.951088      Jeep   \n",
       "3                      ['buyback protection eligible']    5.950127      Jeep   \n",
       "4    ['non-personal use reported', 'buyback protect...   24.672986  Cadillac   \n",
       "..                                                 ...         ...       ...   \n",
       "995                    ['buyback protection eligible']   18.091597      Jeep   \n",
       "996  ['non-personal use reported', 'buyback protect...  167.799676  Cadillac   \n",
       "997  ['accident(s) reported', 'non-personal use rep...   46.215625  Cadillac   \n",
       "998                    ['buyback protection eligible']   14.907535      Jeep   \n",
       "999  ['non-personal use reported', 'buyback protect...  144.833935  Cadillac   \n",
       "\n",
       "    VehMileage       VehModel VehPriceLabel  \\\n",
       "0      13625.0            xt5      gooddeal   \n",
       "1      42553.0  grandcherokee      gooddeal   \n",
       "2      48951.0  grandcherokee      gooddeal   \n",
       "3      44179.0  grandcherokee      gooddeal   \n",
       "4      22269.0            xt5      gooddeal   \n",
       "..         ...            ...           ...   \n",
       "995    24744.0  grandcherokee      gooddeal   \n",
       "996     5699.0            xt5      gooddeal   \n",
       "997    17985.0            xt5      gooddeal   \n",
       "998       27.0  grandcherokee     fairprice   \n",
       "999    23435.0            xt5      gooddeal   \n",
       "\n",
       "                                        VehSellerNotes VehYear  NumOwners  \n",
       "0    Thank you for visiting another one of Lake Keo...    2018        1.0  \n",
       "1    This 2017 Jeep Grand Cherokee 4dr Limited 4x4 ...    2017        1.0  \n",
       "2    Certified. Brilliant Black Crystal Pearlcoat 2...    2015        1.0  \n",
       "3    2015 Jeep Grand Cherokee ***THIS VEHICLE IS AT...    2015        1.0  \n",
       "4    AWD, CarFax One Owner! Navigation, Back-up Cam...    2018        1.0  \n",
       "..                                                 ...     ...        ...  \n",
       "995  granite crystal metallic clearcoat 2017 Jeep G...    2017        1.0  \n",
       "996  Tampa Mitsubishi is proud to offer this attrac...    2017        1.0  \n",
       "997  *BRAND NEW* *2018* *CADILLAC* *XT5** LOADED WI...    2018        1.0  \n",
       "998  Thousand?s of Vehicles, Positively Different E...    2018        1.0  \n",
       "999  Features: 2018 Cadillac XT5 Luxury Red AWD 3.6...    2018        1.0  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_nulls_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nulls = data[[\"Dealer_Listing_Price\", \"Vehicle_Trim\"]]\n",
    "y_train_null_id = y_train_nulls[data.isnull().any(axis=1)].index\n",
    "\n",
    "\n",
    "X_train_nulls_raw = data.drop(\n",
    "    [\"Dealer_Listing_Price\", \"Vehicle_Trim\"], axis=1\n",
    ")  # nulls to indicate nulls present and raw to indicate ft are not numerically encoded yet\n",
    "y_test_id_nulls_raw = X_test_nulls_raw[\"ListingID\"]  # save for later\n",
    "X_test_nulls_raw = X_test_nulls_raw.drop([\"ListingID\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note some features that only have two options and are binarized. Recall that OrdinalEncoder is suitable for categorical variables with a meaningful order. OneHotEncoder is suitable for categorical variables without a natural specific order and can be used to binarize. Seller rating is tricky to deal with as it's a numeric categorical feature as ratings are still an ordinal measure (what does 3.5 rating - 2.0 vs 1.0 + 5.0 rating even mean??) Before we tend to these pipelines simplify the codification of ext/int colors as there is a lot of repetition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['white' 'black' 'silver' 'blue' 'red' 'granite' 'gray' 'brown' 'steel'\n",
      " 'charcoal' 'velvet' 'green' 'bronze' 'rhino' nan 'ivory' 'amethyst'\n",
      " 'sangria' 'maroon' 'cashmere' 'certifiedhemilthrpanoroofnav' 'purple'\n",
      " 'certifiedlthrroofnavcamera' 'burgundy' 'auburn' 'gold' 'grey' 'pearl'\n",
      " 'diamond' 'other' 'midnightsky' 'beige' 'tan' 'notspecified'\n",
      " 'certifiedlthrpanoroofnavcamera' 'platinum' 'pewter' 'mocha'\n",
      " 'shadowmetallic' 'gy' 'certifiedlthrpanoroofhotcoldseats' 'pink' 'billet'\n",
      " 'certifiedroofcamerahtdseats' 'beigh' 'midnightskymetallic' 'unspecified'\n",
      " 'brightsil'] 48\n",
      "['black' 'blue' 'granite' 'silver' 'white' nan 'red' 'beige' 'amethyst'\n",
      " 'gray' 'ivory' 'billet' 'rhino' 'deepcherry' 'sangria' 'bronze' 'green'\n",
      " 'velvet' 'steel' 'cashmere' 'brown' 'auburn' 'grey' 'midnightsky'\n",
      " 'burgundy' 'shadowmetallic' 'tan' 'notspecified' 'diamond' 'undetermined'\n",
      " 'mocha'] 31\n"
     ]
    }
   ],
   "source": [
    "# Words to match and replace with the corresponding color name\n",
    "colors_to_replace = [\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"black\",\n",
    "    \"silver\",\n",
    "    \"white\",\n",
    "    \"cashmere\",\n",
    "    \"steel\",\n",
    "    \"granite\",\n",
    "    \"ivory\",\n",
    "    \"amethyst\",\n",
    "    \"green\",\n",
    "    \"gray\",\n",
    "    \"brown\",\n",
    "    \"bronze\",\n",
    "    \"auburn\",\n",
    "    \"sangria\",\n",
    "    \"mocha\",\n",
    "    \"rhino\",\n",
    "]\n",
    "\n",
    "# Constructing a regular expression pattern to match any portion containing the specified colors\n",
    "pattern = \"|\".join(colors_to_replace)\n",
    "\n",
    "# Replace any portion of the string containing 'blue', 'red', or 'black' etc with only the corresponding color name\n",
    "# The r'\\1' in the value parameter is a backreference to the matched portion, so it replaces the entire string with only the color name.\n",
    "X_train_nulls_raw[\"VehColorExt\"] = X_train_nulls_raw[\"VehColorExt\"].replace(\n",
    "    to_replace=f\".*({pattern}).*\", value=r\"\\1\", regex=True\n",
    ")\n",
    "X_test_nulls_raw[\"VehColorExt\"] = X_test_nulls_raw[\"VehColorExt\"].replace(\n",
    "    to_replace=f\".*({pattern}).*\", value=r\"\\1\", regex=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    X_train_nulls_raw[\"VehColorExt\"].unique(),\n",
    "    len(X_train_nulls_raw[\"VehColorExt\"].unique()),\n",
    ")\n",
    "print(\n",
    "    X_test_nulls_raw[\"VehColorExt\"].unique(),\n",
    "    len(X_test_nulls_raw[\"VehColorExt\"].unique()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['white' 'black' 'silver' 'blue' 'red' 'granite' 'gray' 'brown' 'steel'\n",
      " 'charcoal' 'velvet' 'green' 'bronze' 'rhino' nan 'ivory' 'amethyst'\n",
      " 'sangria' 'maroon' 'cashmere' 'certifiedhemilthrpanoroofnav' 'purple'\n",
      " 'certifiedlthrroofnavcamera' 'burgundy' 'auburn' 'gold' 'grey' 'pearl'\n",
      " 'diamond' 'other' 'midnightsky' 'beige' 'tan' 'notspecified'\n",
      " 'certifiedlthrpanoroofnavcamera' 'platinum' 'pewter' 'mocha'\n",
      " 'shadowmetallic' 'gy' 'certifiedlthrpanoroofhotcoldseats' 'pink' 'billet'\n",
      " 'certifiedroofcamerahtdseats' 'beigh' 'midnightskymetallic' 'unspecified'\n",
      " 'brightsil'] 38\n",
      "['black' 'blue' 'granite' 'silver' 'white' nan 'red' 'beige' 'amethyst'\n",
      " 'gray' 'ivory' 'billet' 'rhino' 'deepcherry' 'sangria' 'bronze' 'green'\n",
      " 'velvet' 'steel' 'cashmere' 'brown' 'auburn' 'grey' 'midnightsky'\n",
      " 'burgundy' 'shadowmetallic' 'tan' 'notspecified' 'diamond' 'undetermined'\n",
      " 'mocha'] 22\n"
     ]
    }
   ],
   "source": [
    "X_train_nulls_raw[\"VehColorInt\"] = X_train_nulls_raw[\"VehColorInt\"].replace(\n",
    "    to_replace=f\".*({pattern}).*\", value=r\"\\1\", regex=True\n",
    ")\n",
    "X_test_nulls_raw[\"VehColorInt\"] = X_test_nulls_raw[\"VehColorInt\"].replace(\n",
    "    to_replace=f\".*({pattern}).*\", value=r\"\\1\", regex=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    X_train_nulls_raw[\"VehColorExt\"].unique(),\n",
    "    len(X_train_nulls_raw[\"VehColorInt\"].unique()),\n",
    ")\n",
    "print(\n",
    "    X_test_nulls_raw[\"VehColorExt\"].unique(),\n",
    "    len(X_test_nulls_raw[\"VehColorInt\"].unique()),\n",
    ")\n",
    "\n",
    "# Careful not to overreach and drop colors you do not see in the test set as it's meant to be beyond our purview. This was simply to cut down on complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['SellerCity', 'SellerIsPriv', 'SellerListSrc', 'SellerName',\n",
       "        'SellerRating', 'SellerRevCnt', 'SellerState', 'SellerZip',\n",
       "        'VehCertified', 'VehColorExt', 'VehColorInt', 'VehDriveTrain',\n",
       "        'VehEngine', 'VehFeats', 'VehFuel', 'VehHistory', 'VehListdays',\n",
       "        'VehMake', 'VehMileage', 'VehModel', 'VehPriceLabel', 'VehSellerNotes',\n",
       "        'VehYear', 'NumOwners'],\n",
       "       dtype='object'),\n",
       " (6294, 24),\n",
       " (1000, 24))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nulls_raw.columns, X_train_nulls_raw.shape, X_test_nulls_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we focus on the text columns and use Word2Vec to study them. I left notes in spark.py if you want more details on rationale (doing it on this end as converting pyspark Vector type is hassle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   None.\n",
       "1       Come take a look at our great pre-owned invent...\n",
       "2       Backed by a rigorous 125-point inspection by f...\n",
       "3       Drop by to see us and you will quickly see how...\n",
       "4       Luxury, Exterior Parking Camera Rear, Front Du...\n",
       "                              ...                        \n",
       "6289    ****ALL BLACK EDITION****You are viewing a bea...\n",
       "6290    CarMax makes car buying easy and hassle-free. ...\n",
       "6291    Clean CARFAX. Certified. Black 2018 Cadillac X...\n",
       "6292    Black 2017 Cadillac XT5 Luxury FWD 8-Speed Aut...\n",
       "6293    With Vroom, you can buy your next car from the...\n",
       "Name: VehSellerNotes, Length: 6294, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nulls_raw[\"VehSellerNotes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x1772ba094e0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(X_train_nulls_raw[\"VehSellerNotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gbert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "# https://www.geeksforgeeks.org/nlp-gensim-tutorial-complete-guide-for-beginners/\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def tokenize(df, col):\n",
    "    df[col] = df[col].fillna(\"none\")\n",
    "    df[col] = df[col].replace(\"\", \"none\")\n",
    "\n",
    "    # remove punctuation and special characters alongside stop words\n",
    "    df[col] = df[col].apply(\n",
    "        lambda text: [\n",
    "            re.sub(r\"[^a-zA-Z0-9]\", \"\", token.lower())\n",
    "            for token in word_tokenize(text)\n",
    "            if token.lower() not in stop_words\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # removing any resulting blank space entries like in  ['arsenic', '', 'cat'] --> ['arsenic', 'cat']\n",
    "    df[col] = df[col].apply(lambda text: \" \".join(text).split())\n",
    "\n",
    "    # now each entry (document) of the col has words in our custom tokenized format:\n",
    "    \"\"\"\n",
    "    DF now looks something like this (train shown here):\n",
    "    0                                               [none]\n",
    "    1    [come, take, look, great, preowned, inventory,...\n",
    "    2    [backed, rigorous, 125point, inspection, facto...\n",
    "    3    [drop, see, us, quickly, see, century, x27, sp...\n",
    "    4    [luxury, exterior, parking, camera, rear, fron...\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    \"\"\"\n",
    "\n",
    "def tagDoc(df, col, tokens_only=False):\n",
    "    tokenize(df, col)\n",
    "    for i, line in enumerate(df[col]):\n",
    "        print(line)\n",
    "        if tokens_only:\n",
    "            yield line\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(line, [i])\n",
    "\n",
    "\n",
    "def trainedWordModel(train, col, vector_size=100, min_count=3, epochs=40):\n",
    "    model = gensim.models.doc2vec.Doc2Vec(\n",
    "        vector_size=vector_size, min_count=min_count, epochs=epochs\n",
    "    )\n",
    "    train_corpus = tagDoc(train, col, tokens_only=False)\n",
    "\n",
    "    # Essentially, the vocabulary is a list (accessible via model.wv.index_to_key)\n",
    "    # of all of the unique words extracted from the training corpus.\n",
    "    model.build_vocab(train_corpus)\n",
    "\n",
    "    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    # Now, we can use the trained model to infer a vector for any piece of text by passing a list of words to the model.infer_vector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(tagDoc(X_train_nulls_raw, \"VehSellerNotes\", tokens_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gbert\\Desktop\\boing\\src\\imputationEDA.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(train_corpus[:\u001b[39m2\u001b[39;49m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gbert\\Desktop\\boing\\src\\imputationEDA.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainedWordModel(X_train_nulls_raw, \u001b[39m\"\u001b[39;49m\u001b[39mVehSellerNotes\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\gbert\\Desktop\\boing\\src\\imputationEDA.ipynb Cell 20\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m train_corpus \u001b[39m=\u001b[39m tagDoc(train, col, tokens_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Essentially, the vocabulary is a list (accessible via model.wv.index_to_key)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# of all of the unique words extracted from the training corpus.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m model\u001b[39m.\u001b[39;49mbuild_vocab(train_corpus)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m model\u001b[39m.\u001b[39mtrain(train_corpus, total_examples\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mcorpus_count, epochs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mepochs)\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\doc2vec.py:882\u001b[0m, in \u001b[0;36mDoc2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_vocab\u001b[39m(\n\u001b[0;32m    842\u001b[0m         \u001b[39mself\u001b[39m, corpus_iterable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, corpus_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, update\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, progress_per\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m,\n\u001b[0;32m    843\u001b[0m         keep_raw_vocab\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, trim_rule\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    844\u001b[0m     ):\n\u001b[0;32m    845\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build vocabulary from a sequence of documents (can be a once-only generator stream).\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \n\u001b[0;32m    847\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m \n\u001b[0;32m    881\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m     total_words, corpus_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_vocab(\n\u001b[0;32m    883\u001b[0m         corpus_iterable\u001b[39m=\u001b[39;49mcorpus_iterable, corpus_file\u001b[39m=\u001b[39;49mcorpus_file,\n\u001b[0;32m    884\u001b[0m         progress_per\u001b[39m=\u001b[39;49mprogress_per, trim_rule\u001b[39m=\u001b[39;49mtrim_rule,\n\u001b[0;32m    885\u001b[0m     )\n\u001b[0;32m    886\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus_count \u001b[39m=\u001b[39m corpus_count\n\u001b[0;32m    887\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus_total_words \u001b[39m=\u001b[39m total_words\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\doc2vec.py:1054\u001b[0m, in \u001b[0;36mDoc2Vec.scan_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m corpus_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1052\u001b[0m     corpus_iterable \u001b[39m=\u001b[39m TaggedLineDocument(corpus_file)\n\u001b[1;32m-> 1054\u001b[0m total_words, corpus_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scan_vocab(corpus_iterable, progress_per, trim_rule)\n\u001b[0;32m   1056\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   1057\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcollected \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m word types and \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m unique tags from a corpus of \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m examples and \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m words\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1058\u001b[0m     \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_vocab), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdv), corpus_count, total_words,\n\u001b[0;32m   1059\u001b[0m )\n\u001b[0;32m   1061\u001b[0m \u001b[39mreturn\u001b[39;00m total_words, corpus_count\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\doc2vec.py:954\u001b[0m, in \u001b[0;36mDoc2Vec._scan_vocab\u001b[1;34m(self, corpus_iterable, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m    952\u001b[0m doctags_lookup \u001b[39m=\u001b[39m {}\n\u001b[0;32m    953\u001b[0m doctags_list \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 954\u001b[0m \u001b[39mfor\u001b[39;00m document_no, document \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(corpus_iterable):\n\u001b[0;32m    955\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m checked_string_types:\n\u001b[0;32m    956\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(document\u001b[39m.\u001b[39mwords, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;32mc:\\Users\\gbert\\Desktop\\boing\\src\\imputationEDA.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtagDoc\u001b[39m(df, col, tokens_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     tokenize(df, col)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(df[col]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         \u001b[39mprint\u001b[39m(line)\n",
      "\u001b[1;32mc:\\Users\\gbert\\Desktop\\boing\\src\\imputationEDA.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# remove punctuation and special characters alongside stop words\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m text: [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         re\u001b[39m.\u001b[39;49msub(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m[^a-zA-Z0-9]\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, token\u001b[39m.\u001b[39;49mlower())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;49;00m token \u001b[39min\u001b[39;49;00m word_tokenize(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mif\u001b[39;49;00m token\u001b[39m.\u001b[39;49mlower() \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m stop_words\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# removing any resulting blank space entries like in  ['arsenic', '', 'cat'] --> ['arsenic', 'cat']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m text: \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(text)\u001b[39m.\u001b[39msplit())\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gbert\\Desktop\\boing\\src\\imputationEDA.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# remove punctuation and special characters alongside stop words\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mapply(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m text: [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[^a-zA-Z0-9]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, token\u001b[39m.\u001b[39mlower())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m word_tokenize(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# removing any resulting blank space entries like in  ['arsenic', '', 'cat'] --> ['arsenic', 'cat']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gbert/Desktop/boing/src/imputationEDA.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df[col] \u001b[39m=\u001b[39m df[col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m text: \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(text)\u001b[39m.\u001b[39msplit())\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m, preserve_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtokenizers/punkt/\u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39;49mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1281\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, realign_boundaries: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m   1278\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[39m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentences_from_text(text, realign_boundaries))\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, realign_boundaries: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[39m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[39m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[39m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[39m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[39mreturn\u001b[39;00m [text[s:e] \u001b[39mfor\u001b[39;49;00m s, e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, realign_boundaries: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[39m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[39m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[39m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[39m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[39mreturn\u001b[39;00m [text[s:e] \u001b[39mfor\u001b[39;00m s, e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[39mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1328\u001b[0m     slices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1329\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m slices:\n\u001b[0;32m   1330\u001b[0m     \u001b[39myield\u001b[39;00m (sentence\u001b[39m.\u001b[39mstart, sentence\u001b[39m.\u001b[39mstop)\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \u001b[39mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[39mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m realign \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1459\u001b[0m \u001b[39mfor\u001b[39;00m sentence1, sentence2 \u001b[39min\u001b[39;00m _pair_iter(slices):\n\u001b[0;32m   1460\u001b[0m     sentence1 \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(sentence1\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m realign, sentence1\u001b[39m.\u001b[39mstop)\n\u001b[0;32m   1461\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sentence2:\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    319\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(iterator)\n\u001b[0;32m    320\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     prev \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1431\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_slices_from_text\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mslice\u001b[39m]:\n\u001b[0;32m   1430\u001b[0m     last_break \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1431\u001b[0m     \u001b[39mfor\u001b[39;00m match, context \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_potential_end_contexts(text):\n\u001b[0;32m   1432\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[0;32m   1433\u001b[0m             \u001b[39myield\u001b[39;00m \u001b[39mslice\u001b[39m(last_break, match\u001b[39m.\u001b[39mend())\n",
      "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m previous_slice \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m   1394\u001b[0m previous_match \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1395\u001b[0m \u001b[39mfor\u001b[39;00m match \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lang_vars\u001b[39m.\u001b[39;49mperiod_context_re()\u001b[39m.\u001b[39;49mfinditer(text):\n\u001b[0;32m   1396\u001b[0m \n\u001b[0;32m   1397\u001b[0m     \u001b[39m# Get the slice of the previous word\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     before_text \u001b[39m=\u001b[39m text[previous_slice\u001b[39m.\u001b[39mstop : match\u001b[39m.\u001b[39mstart()]\n\u001b[0;32m   1399\u001b[0m     index_after_last_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_last_whitespace_index(before_text)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "trainedWordModel(X_train_nulls_raw, \"VehSellerNotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we just are encoding here there is no danger in leakage (not true if adding ML model predictions as another step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nulls = pd.concat([X_train_nulls_raw, X_test_nulls_raw])\n",
    "X_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nulls.columns, len(X_nulls.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define column subsets\n",
    "categorical_cols = [\n",
    "    \"SellerIsPriv\",\n",
    "    \"SellerListSrc\",\n",
    "    \"SellerState\",\n",
    "    \"SellerZip\",\n",
    "    \"VehCertified\",\n",
    "    \"VehColorExt\",\n",
    "    \"VehColorInt\",\n",
    "    \"VehDriveTrain\",\n",
    "    \"VehEngine\",\n",
    "    \"VehFeats\",\n",
    "    \"VehFuel\",\n",
    "    \"VehHistory\",\n",
    "    \"VehMake\",\n",
    "    \"VehModel\",\n",
    "]\n",
    "ordinal_cols = [\"SellerRating\", \"VehPriceLabel\"]\n",
    "numeric_cols = [\"SellerRevCnt\", \"VehListdays\", \"VehMileage\", \"VehYear\", \"NumOwners\"]\n",
    "\n",
    "# Create transformers\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        # (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"onehot\",\n",
    "            OneHotEncoder(handle_unknown=\"infrequent_if_exist\", sparse_output=False),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        # (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"ordinal\",\n",
    "            OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        # (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=True)),\n",
    "    ]  # https://stackoverflow.com/questions/52008548/python-running-into-x-test-y-test-fit-errors\n",
    ")\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "        (\"ord\", ordinal_transformer, ordinal_cols),\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # NOTE CRITICAL -- leave the other features not explicitly called as is but make sure all cols accounted for\n",
    ")\n",
    "\n",
    "# Create a final pipeline with the preprocessor and any subsequent steps (e.g., a model)\n",
    "final_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        # Add additional steps as needed, e.g., a machine learning model -- holding off as we want to do imputation study\n",
    "    ]\n",
    ")\n",
    "X = final_pipeline.fit_transform(X_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any([arrayOfArrayElement is np.nan for arrayOfArrayElement in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nulls = X[: len(X_train_nulls_raw)]  # drop raw as now encoded\n",
    "X_test_nulls = X[len(X_train_nulls_raw) :]\n",
    "X_train_nulls.shape, X_test_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_array = np.zeros(3, dtype=object)\n",
    "\n",
    "# Example NumPy array to assign to the first index\n",
    "array_to_assign = np.array([1, 2, 3], dtype=object)\n",
    "\n",
    "# Example string list to assign to the second index\n",
    "list_to_assign = 3\n",
    "\n",
    "# Assign the NumPy array to the first index\n",
    "original_array[0] = array_to_assign\n",
    "\n",
    "# Assign the string list to the second index\n",
    "original_array[1] = list_to_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any([arrayOfArrayElement is np.nan for arrayOfArrayElement in original_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nulls[3206]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have encoded the data let's take a look at the distributions (without the compression from encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distCol = [\n",
    "    \"VehListdays\",\n",
    "    \"VehMileage\",\n",
    "    \"NumOwners\",\n",
    "    \"SellerRating\",\n",
    "    \"SellerRevCnt\",\n",
    "]\n",
    "# Set up subplots -- NOTE: Dealer_Listing_Price is part of what we want to predict!\n",
    "fig, axes = plt.subplots(nrows=len(distCol), ncols=1, figsize=(8, 4 * len(distCol)))\n",
    "\n",
    "## Plot distribution and statistics for each column\n",
    "for i, column in enumerate(distCol):\n",
    "    # Plot distribution\n",
    "    sns.histplot(X_train_nulls_raw[column], kde=True, ax=axes[i])\n",
    "\n",
    "    # Calculate statistics\n",
    "    mean_value = X_train_nulls_raw[column].mean()\n",
    "    median_value = X_train_nulls_raw[column].median()\n",
    "    std_dev_value = X_train_nulls_raw[column].std()\n",
    "\n",
    "    # Plot major statistics below the distribution plot\n",
    "    axes[i].axvline(\n",
    "        mean_value,\n",
    "        color=\"red\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=f\"Mean ({mean_value:.2f})\",\n",
    "    )\n",
    "    axes[i].axvline(\n",
    "        median_value,\n",
    "        color=\"green\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=f\"Median ({median_value:.2f})\",\n",
    "    )\n",
    "    axes[i].axvline(\n",
    "        mean_value + std_dev_value,\n",
    "        color=\"orange\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=f\"Std Dev ({std_dev_value:.2f})\",\n",
    "    )\n",
    "    axes[i].axvline(\n",
    "        mean_value - std_dev_value, color=\"orange\", linestyle=\"dashed\", linewidth=2\n",
    "    )\n",
    "    axes[i].legend()\n",
    "\n",
    "    # Set x-axis limits to the minimum and maximum values of the distribution\n",
    "    axes[i].set_xlim(X_train_nulls_raw[column].min(), X_train_nulls_raw[column].max())\n",
    "\n",
    "    # Set plot labels and title\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "    axes[i].set_title(f\"Distribution of {column}\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up subplots\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot distribution\n",
    "sns.histplot(y_train_nulls[\"Dealer_Listing_Price\"], kde=True, ax=ax)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_value = y_train_nulls[\"Dealer_Listing_Price\"].mean()\n",
    "median_value = y_train_nulls[\"Dealer_Listing_Price\"].median()\n",
    "std_dev_value = y_train_nulls[\"Dealer_Listing_Price\"].std()\n",
    "\n",
    "# Plot major statistics below the distribution plot\n",
    "ax.axvline(\n",
    "    mean_value,\n",
    "    color=\"red\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=2,\n",
    "    label=f\"Mean ({mean_value:.2f})\",\n",
    ")\n",
    "ax.axvline(\n",
    "    median_value,\n",
    "    color=\"green\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=2,\n",
    "    label=f\"Median ({median_value:.2f})\",\n",
    ")\n",
    "ax.axvline(\n",
    "    mean_value + std_dev_value,\n",
    "    color=\"orange\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=2,\n",
    "    label=f\"Std Dev ({std_dev_value:.2f})\",\n",
    ")\n",
    "ax.axvline(mean_value - std_dev_value, color=\"orange\", linestyle=\"dashed\", linewidth=2)\n",
    "ax.legend()\n",
    "\n",
    "# Set x-axis limits to the minimum and maximum values of the distribution\n",
    "ax.set_xlim(\n",
    "    y_train_nulls[\"Dealer_Listing_Price\"].min(),\n",
    "    y_train_nulls[\"Dealer_Listing_Price\"].max(),\n",
    ")\n",
    "\n",
    "# Set plot labels and title\n",
    "ax.set_xlabel(\"Dealer_Listing_Price\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Distribution of Dealer_Listing_Price\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the data distributions look Gaussian but standard scaling will be used as it will not change the shape of the distribution.\n",
    "\n",
    "https://stats.stackexchange.com/questions/453211/using-standardscaler-function-of-scikit-learn-library\n",
    "https://stats.stackexchange.com/questions/290958/logistic-regression-and-scaling-of-features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is time to impute missing data before we drop certain rows due to outliers, say, outside 3 std dev from in-column averages. We shall use a random forest model (less sensitive to outliers present) as a baseline model for imputation though other NN-backed methods can be explored and explore various imputers.\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First want to get a score on a dataset which had no missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by getting the data into numerical input schemes for missing data (nulls). To do this and avoid data leakage, we need the statistics calculated for each column are calculated on the training dataset only, then applied to the train and test sets for each fold in the dataset under consideration. For the sake of time we will use a Random Forest regressor as the baseline imputation model. Other approaches can develop a NN-backed approach instead or use other ensemble methods.\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
